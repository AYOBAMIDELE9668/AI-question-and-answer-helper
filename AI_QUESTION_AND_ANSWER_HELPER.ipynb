{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z_f0cBvcX9NK"
      },
      "outputs": [],
      "source": [
        "!mkdir -p app\n",
        "!mkdir -p tests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn python-dotenv requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGARKhOGYKEg",
        "outputId": "abe9410f-0fab-4a6c-c7ea-a5d11f766f3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "fastapi==0.100.0\n",
        "uvicorn==0.22.0\n",
        "python-dotenv==1.0.0\n",
        "requests==2.31.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9sNmafIYQy_",
        "outputId": "0a80348a-3591-4b3c-bd26-652c607b29e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/__init__.py\n",
        "__all__ = [\"main\", \"agent\", \"tools\", \"memory\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCW_59vwYagY",
        "outputId": "28acdf0a-9fe5-4357-e56b-b84a2aad0c21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/tools.py\n",
        "from typing import Optional\n",
        "\n",
        "# Simple knowledge base\n",
        "KB = {\n",
        "    \"python\": \"Python is a high-level, interpreted programming language.\",\n",
        "    \"fastapi\": \"FastAPI is a fast Python framework for building APIs.\",\n",
        "    \"uvicorn\": \"Uvicorn is a lightning-fast ASGI server for Python.\",\n",
        "    \"ai\": \"AI (Artificial Intelligence) is the simulation of human intelligence by machines.\"\n",
        "}\n",
        "\n",
        "def search_tool(query: str) -> Optional[str]:\n",
        "    \"\"\"Very simple keyword-based search tool.\"\"\"\n",
        "    q = query.lower().strip()\n",
        "\n",
        "    if q in KB:\n",
        "        return KB[q]\n",
        "\n",
        "    for key, value in KB.items():\n",
        "        if key in q:\n",
        "            return value\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6CC2cYnYfao",
        "outputId": "6853bc40-8935-45bd-b72e-6c8fc8c23646"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/tools.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/memory.py\n",
        "from collections import deque\n",
        "from typing import List\n",
        "\n",
        "class ShortTermMemory:\n",
        "    \"\"\"Stores the last few messages to maintain context.\"\"\"\n",
        "    def __init__(self, capacity: int = 3):\n",
        "        self.capacity = capacity\n",
        "        self.messages = deque(maxlen=capacity)\n",
        "\n",
        "    def add(self, message: str):\n",
        "        self.messages.append(message)\n",
        "\n",
        "    def get_context(self) -> List[str]:\n",
        "        return list(self.messages)\n",
        "\n",
        "    def clear(self):\n",
        "        self.messages.clear()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ostkhSJBYpTv",
        "outputId": "7541c0cc-733f-4d30-d672-956f63b91614"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/memory.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/agent.py\n",
        "from typing import Dict, Any\n",
        "from .tools import search_tool\n",
        "from .memory import ShortTermMemory\n",
        "\n",
        "memory = ShortTermMemory(capacity=3)\n",
        "\n",
        "def is_factual_question(message: str) -> bool:\n",
        "    \"\"\"Simple detection of factual questions using keywords.\"\"\"\n",
        "    message = message.lower()\n",
        "    question_words = [\"what\", \"when\", \"who\", \"where\", \"which\", \"explain\", \"define\"]\n",
        "\n",
        "    if any(message.startswith(w) for w in question_words):\n",
        "        return True\n",
        "\n",
        "    if \"about\" in message:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def generate_conversational_reply(message: str, context: list) -> str:\n",
        "    \"\"\"Very simple conversational response.\"\"\"\n",
        "    if \"hi\" in message.lower() or \"hello\" in message.lower():\n",
        "        return \"Hey! How can I help you today?\"\n",
        "    return \"Got it! You can ask me a factual question like 'What is Python?'.\"\n",
        "\n",
        "def agent_respond(message: str) -> Dict[str, Any]:\n",
        "    memory.add(f\"user: {message}\")\n",
        "\n",
        "    factual = is_factual_question(message)\n",
        "\n",
        "    response = {\n",
        "        \"input\": message,\n",
        "        \"factual\": factual,\n",
        "        \"tool_used\": False,\n",
        "        \"answer\": None,\n",
        "        \"context\": memory.get_context()\n",
        "    }\n",
        "\n",
        "    if factual:\n",
        "        tool_answer = search_tool(message)\n",
        "        if tool_answer:\n",
        "            response[\"tool_used\"] = True\n",
        "            response[\"answer\"] = tool_answer\n",
        "            memory.add(f\"agent: {tool_answer}\")\n",
        "            return response\n",
        "\n",
        "    reply = generate_conversational_reply(message, memory.get_context())\n",
        "    response[\"answer\"] = reply\n",
        "    memory.add(f\"agent: {reply}\")\n",
        "    return response\n",
        "\n",
        "def reset_memory():\n",
        "    memory.clear()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9PTFM3lYztu",
        "outputId": "53b6b0ba-f693-4319-8d80-dca345afd45a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app/main.py\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from .agent import agent_respond, reset_memory\n",
        "\n",
        "app = FastAPI(title=\"AI Question-Answer Helper\")\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "\n",
        "class ChatResponse(BaseModel):\n",
        "    input: str\n",
        "    factual: bool\n",
        "    tool_used: bool\n",
        "    answer: str\n",
        "    context: list\n",
        "\n",
        "@app.post(\"/chat\", response_model=ChatResponse)\n",
        "async def chat(req: ChatRequest):\n",
        "    if not req.message.strip():\n",
        "        raise HTTPException(status_code=400, detail=\"Message cannot be empty\")\n",
        "\n",
        "    reply = agent_respond(req.message)\n",
        "    return ChatResponse(**reply)\n",
        "\n",
        "@app.post(\"/reset-memory\")\n",
        "async def reset():\n",
        "    reset_memory()\n",
        "    return {\"status\": \"ok\", \"message\": \"Memory cleared\"}\n",
        "\n",
        "# Run with:\n",
        "# uvicorn app.main:app --reload --port=8000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uaxp-td8Y5rQ",
        "outputId": "db9307e8-8d24-4382-adc4-0e7ae06ba804"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn nest_asyncio pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGbFrBhXaFDw",
        "outputId": "72ca5641-e9cd-45e8-fdfd-f7b737d6bccb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from threading import Thread\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def home():\n",
        "    return {\"message\": \"API running!\"}\n",
        "\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "Thread(target=run).start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8L90PUHaRja",
        "outputId": "5fb8f1f6-0dc8-4d49-8cab-326331185537"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [164]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(\"http://localhost:8000/\")\n",
        "response.json()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgMdti14aws3",
        "outputId": "3de96b9c-0eb0-458c-8914-aa2b7d8b65fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37696 - \"GET / HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'API running!'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from app.agent import agent_respond\n",
        "\n",
        "print(agent_respond(\"who is the president of nigeria\"))\n",
        "print(agent_respond(\"tell me something about football\"))\n",
        "print(agent_respond(\"how many states are in nigeria\"))\n",
        "print(agent_respond(\"ok cool, continue\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJqG97jWdRR5",
        "outputId": "cacc0664-3862-4024-d6f2-e1a502dea202"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'who is the president of nigeria', 'factual': True, 'tool_used': False, 'answer': \"Got it! You can ask me a factual question like 'What is Python?'.\", 'context': ['user: ok cool, continue', \"agent: Got it! You can ask me a factual question like 'What is Python?'.\", 'user: who is the president of nigeria']}\n",
            "{'input': 'tell me something about football', 'factual': True, 'tool_used': False, 'answer': 'Hey! How can I help you today?', 'context': ['user: who is the president of nigeria', \"agent: Got it! You can ask me a factual question like 'What is Python?'.\", 'user: tell me something about football']}\n",
            "{'input': 'how many states are in nigeria', 'factual': False, 'tool_used': False, 'answer': \"Got it! You can ask me a factual question like 'What is Python?'.\", 'context': ['user: tell me something about football', 'agent: Hey! How can I help you today?', 'user: how many states are in nigeria']}\n",
            "{'input': 'ok cool, continue', 'factual': False, 'tool_used': False, 'answer': \"Got it! You can ask me a factual question like 'What is Python?'.\", 'context': ['user: how many states are in nigeria', \"agent: Got it! You can ask me a factual question like 'What is Python?'.\", 'user: ok cool, continue']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from threading import Thread\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "from app.agent import agent_respond\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "async def chat(req: ChatRequest):\n",
        "    return agent_respond(req.message)\n",
        "\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "Thread(target=run).start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMIgyhsghHhX",
        "outputId": "1f8c34e3-98e6-4f88-a822-b1b08274ca3b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [164]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.post(\n",
        "    \"http://127.0.0.1:8000/chat\",\n",
        "    json={\"message\": \"who is the president of nigeria\"}\n",
        ")\n",
        "response.json()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fverKtxvhRfP",
        "outputId": "1a0f2baf-3253-4f06-dde3-53a8c194733f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50570 - \"POST /chat HTTP/1.1\" 404 Not Found\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detail': 'Not Found'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install fastapi uvicorn nest_asyncio requests\n",
        "\n",
        "# ----------------------------\n",
        "# Step 1: Define agent functions\n",
        "# ----------------------------\n",
        "memory = []\n",
        "\n",
        "def add_to_memory(user_msg, assistant_msg):\n",
        "    memory.append({\"user\": user_msg, \"assistant\": assistant_msg})\n",
        "    if len(memory) > 5:\n",
        "        memory.pop(0)\n",
        "\n",
        "# Small knowledge base\n",
        "knowledge_base = {\n",
        "    \"python\": \"Python is a high-level, interpreted programming language.\",\n",
        "    \"fastapi\": \"FastAPI is a fast Python framework for building APIs.\",\n",
        "    \"uvicorn\": \"Uvicorn is a lightning-fast ASGI server for Python.\",\n",
        "    \"ai\": \"AI (Artificial Intelligence) is the simulation of human intelligence by machines.\",\n",
        "}\n",
        "\n",
        "def search_tool(query):\n",
        "    q = query.lower().strip()\n",
        "    return knowledge_base.get(q, None)\n",
        "\n",
        "def agent_respond(message):\n",
        "    # Check factual\n",
        "    tool_answer = search_tool(message)\n",
        "    if tool_answer:\n",
        "        add_to_memory(message, tool_answer)\n",
        "        return {\n",
        "            \"input\": message,\n",
        "            \"factual\": True,\n",
        "            \"tool_used\": True,\n",
        "            \"answer\": tool_answer,\n",
        "            \"context\": memory\n",
        "        }\n",
        "\n",
        "    # Fallback conversational\n",
        "    reply = f\"Got it! You can ask me a factual question like 'What is Python?'.\"\n",
        "    add_to_memory(message, reply)\n",
        "    return {\n",
        "        \"input\": message,\n",
        "        \"factual\": False,\n",
        "        \"tool_used\": False,\n",
        "        \"answer\": reply,\n",
        "        \"context\": memory\n",
        "    }\n",
        "\n",
        "# ----------------------------\n",
        "# Step 2: Start FastAPI\n",
        "# ----------------------------\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from threading import Thread\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI(title=\"AI Question-Answer Helper\")\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    print(\" FastAPI server has started successfully!\")\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "async def chat(req: ChatRequest):\n",
        "    return agent_respond(req.message)\n",
        "\n",
        "def run():\n",
        "    # Changed port to 8001 to avoid conflicts\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8001)\n",
        "\n",
        "# Start FastAPI in background thread\n",
        "Thread(target=run).start()\n",
        "\n",
        "# ----------------------------\n",
        "# Step 3: Test multiple queries\n",
        "# ----------------------------\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Wait a few seconds for the server to start\n",
        "time.sleep(3)\n",
        "\n",
        "test_queries = [\n",
        "    \"What is Python?\",\n",
        "    \"Tell me about AI\",\n",
        "    \"Who is the president of Nigeria?\",\n",
        "    \"Hello there!\",\n",
        "    \"What is FastAPI?\"\n",
        "]\n",
        "\n",
        "print(\"===== Testing /chat endpoint =====\\n\")\n",
        "for query in test_queries:\n",
        "    # Updated port in the request URL\n",
        "    response = requests.post(\n",
        "        \"http://127.0.0.1:8001/chat\",\n",
        "        json={\"message\": query}\n",
        "    )\n",
        "    print(f\"User: {query}\")\n",
        "    # Added error handling for responses that don't contain 'answer'\n",
        "    try:\n",
        "        print(f\"Agent: {response.json()['answer']}\\n\")\n",
        "    except KeyError:\n",
        "        print(f\"Agent: Error - Status Code: {response.status_code}, Detail: {response.json().get('detail', 'No detail provided')}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Agent: An unexpected error occurred: {e}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za3anesZkAUU",
        "outputId": "b3944603-bc46-4425-b6a1-afc4d3676a94"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-41' coro=<Server.serve() done, defined at /usr/local/lib/python3.12/dist-packages/uvicorn/server.py:69> exception=SystemExit(1)>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 164, in startup\n",
            "    server = await loop.create_server(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1584, in create_server\n",
            "    raise OSError(err.errno, msg) from None\n",
            "OSError: [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): [errno 98] address already in use\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/tmp/ipython-input-3657850984.py\", line 75, in run\n",
            "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 593, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 396, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 303, in __step\n",
            "    self.__step_run_and_handle_result(exc)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 71, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 86, in _serve\n",
            "    await self.startup(sockets=sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 174, in startup\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2612402754.py:66: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n",
            "INFO:     Started server process [164]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FastAPI server has started successfully!\n",
            "===== Testing /chat endpoint =====\n",
            "\n",
            "INFO:     127.0.0.1:50200 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "User: What is Python?\n",
            "Agent: Got it! You can ask me a factual question like 'What is Python?'.\n",
            "\n",
            "INFO:     127.0.0.1:50210 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "User: Tell me about AI\n",
            "Agent: Got it! You can ask me a factual question like 'What is Python?'.\n",
            "\n",
            "INFO:     127.0.0.1:50212 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "User: Who is the president of Nigeria?\n",
            "Agent: Got it! You can ask me a factual question like 'What is Python?'.\n",
            "\n",
            "INFO:     127.0.0.1:50214 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "User: Hello there!\n",
            "Agent: Got it! You can ask me a factual question like 'What is Python?'.\n",
            "\n",
            "INFO:     127.0.0.1:50216 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "User: What is FastAPI?\n",
            "Agent: Got it! You can ask me a factual question like 'What is Python?'.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}