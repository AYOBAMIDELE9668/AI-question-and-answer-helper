# -*- coding: utf-8 -*-
"""AI QUESTION AND ANSWER HELPER

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v3HMIWb7yioaMefmIRbS4qlxFwxnjbaH
"""

!mkdir -p app
!mkdir -p tests

!pip install fastapi uvicorn python-dotenv requests

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# fastapi==0.100.0
# uvicorn==0.22.0
# python-dotenv==1.0.0
# requests==2.31.0
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app/__init__.py
# __all__ = ["main", "agent", "tools", "memory"]
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app/tools.py
# from typing import Optional
# 
# # Simple knowledge base
# KB = {
#     "python": "Python is a high-level, interpreted programming language.",
#     "fastapi": "FastAPI is a fast Python framework for building APIs.",
#     "uvicorn": "Uvicorn is a lightning-fast ASGI server for Python.",
#     "ai": "AI (Artificial Intelligence) is the simulation of human intelligence by machines."
# }
# 
# def search_tool(query: str) -> Optional[str]:
#     """Very simple keyword-based search tool."""
#     q = query.lower().strip()
# 
#     if q in KB:
#         return KB[q]
# 
#     for key, value in KB.items():
#         if key in q:
#             return value
# 
#     return None
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app/memory.py
# from collections import deque
# from typing import List
# 
# class ShortTermMemory:
#     """Stores the last few messages to maintain context."""
#     def __init__(self, capacity: int = 3):
#         self.capacity = capacity
#         self.messages = deque(maxlen=capacity)
# 
#     def add(self, message: str):
#         self.messages.append(message)
# 
#     def get_context(self) -> List[str]:
#         return list(self.messages)
# 
#     def clear(self):
#         self.messages.clear()
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app/agent.py
# from typing import Dict, Any
# from .tools import search_tool
# from .memory import ShortTermMemory
# 
# memory = ShortTermMemory(capacity=3)
# 
# def is_factual_question(message: str) -> bool:
#     """Simple detection of factual questions using keywords."""
#     message = message.lower()
#     question_words = ["what", "when", "who", "where", "which", "explain", "define"]
# 
#     if any(message.startswith(w) for w in question_words):
#         return True
# 
#     if "about" in message:
#         return True
# 
#     return False
# 
# def generate_conversational_reply(message: str, context: list) -> str:
#     """Very simple conversational response."""
#     if "hi" in message.lower() or "hello" in message.lower():
#         return "Hey! How can I help you today?"
#     return "Got it! You can ask me a factual question like 'What is Python?'."
# 
# def agent_respond(message: str) -> Dict[str, Any]:
#     memory.add(f"user: {message}")
# 
#     factual = is_factual_question(message)
# 
#     response = {
#         "input": message,
#         "factual": factual,
#         "tool_used": False,
#         "answer": None,
#         "context": memory.get_context()
#     }
# 
#     if factual:
#         tool_answer = search_tool(message)
#         if tool_answer:
#             response["tool_used"] = True
#             response["answer"] = tool_answer
#             memory.add(f"agent: {tool_answer}")
#             return response
# 
#     reply = generate_conversational_reply(message, memory.get_context())
#     response["answer"] = reply
#     memory.add(f"agent: {reply}")
#     return response
# 
# def reset_memory():
#     memory.clear()
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app/main.py
# from fastapi import FastAPI, HTTPException
# from pydantic import BaseModel
# from .agent import agent_respond, reset_memory
# 
# app = FastAPI(title="AI Question-Answer Helper")
# 
# class ChatRequest(BaseModel):
#     message: str
# 
# class ChatResponse(BaseModel):
#     input: str
#     factual: bool
#     tool_used: bool
#     answer: str
#     context: list
# 
# @app.post("/chat", response_model=ChatResponse)
# async def chat(req: ChatRequest):
#     if not req.message.strip():
#         raise HTTPException(status_code=400, detail="Message cannot be empty")
# 
#     reply = agent_respond(req.message)
#     return ChatResponse(**reply)
# 
# @app.post("/reset-memory")
# async def reset():
#     reset_memory()
#     return {"status": "ok", "message": "Memory cleared"}
# 
# # Run with:
# # uvicorn app.main:app --reload --port=8000
#

!pip install fastapi uvicorn nest_asyncio pyngrok

import nest_asyncio
import uvicorn
from fastapi import FastAPI
from threading import Thread

nest_asyncio.apply()

app = FastAPI()

@app.get("/")
def home():
    return {"message": "API running!"}

def run():
    uvicorn.run(app, host="0.0.0.0", port=8000)

Thread(target=run).start()

import requests

response = requests.get("http://localhost:8000/")
response.json()

from app.agent import agent_respond

print(agent_respond("who is the president of nigeria"))
print(agent_respond("tell me something about football"))
print(agent_respond("how many states are in nigeria"))
print(agent_respond("ok cool, continue"))

import nest_asyncio
import uvicorn
from fastapi import FastAPI
from threading import Thread

nest_asyncio.apply()

app = FastAPI()

from app.agent import agent_respond
from pydantic import BaseModel

class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
async def chat(req: ChatRequest):
    return agent_respond(req.message)

def run():
    uvicorn.run(app, host="0.0.0.0", port=8000)

Thread(target=run).start()

import requests

response = requests.post(
    "http://127.0.0.1:8000/chat",
    json={"message": "who is the president of nigeria"}
)
response.json()

# Install necessary packages
!pip install fastapi uvicorn nest_asyncio requests

# ----------------------------
# Step 1: Define agent functions
# ----------------------------
memory = []

def add_to_memory(user_msg, assistant_msg):
    memory.append({"user": user_msg, "assistant": assistant_msg})
    if len(memory) > 5:
        memory.pop(0)

# Small knowledge base
knowledge_base = {
    "python": "Python is a high-level, interpreted programming language.",
    "fastapi": "FastAPI is a fast Python framework for building APIs.",
    "uvicorn": "Uvicorn is a lightning-fast ASGI server for Python.",
    "ai": "AI (Artificial Intelligence) is the simulation of human intelligence by machines.",
}

def search_tool(query):
    q = query.lower().strip()
    return knowledge_base.get(q, None)

def agent_respond(message):
    # Check factual
    tool_answer = search_tool(message)
    if tool_answer:
        add_to_memory(message, tool_answer)
        return {
            "input": message,
            "factual": True,
            "tool_used": True,
            "answer": tool_answer,
            "context": memory
        }

    # Fallback conversational
    reply = f"Got it! You can ask me a factual question like 'What is Python?'."
    add_to_memory(message, reply)
    return {
        "input": message,
        "factual": False,
        "tool_used": False,
        "answer": reply,
        "context": memory
    }

# ----------------------------
# Step 2: Start FastAPI
# ----------------------------
import nest_asyncio
import uvicorn
from fastapi import FastAPI
from pydantic import BaseModel
from threading import Thread

nest_asyncio.apply()

app = FastAPI(title="AI Question-Answer Helper")

class ChatRequest(BaseModel):
    message: str

@app.on_event("startup")
async def startup_event():
    print(" FastAPI server has started successfully!")

@app.post("/chat")
async def chat(req: ChatRequest):
    return agent_respond(req.message)

def run():
    # Changed port to 8001 to avoid conflicts
    uvicorn.run(app, host="0.0.0.0", port=8001)

# Start FastAPI in background thread
Thread(target=run).start()

# ----------------------------
# Step 3: Test multiple queries
# ----------------------------
import time
import requests

# Wait a few seconds for the server to start
time.sleep(3)

test_queries = [
    "What is Python?",
    "Tell me about AI",
    "Who is the president of Nigeria?",
    "Hello there!",
    "What is FastAPI?"
]

print("===== Testing /chat endpoint =====\n")
for query in test_queries:
    # Updated port in the request URL
    response = requests.post(
        "http://127.0.0.1:8001/chat",
        json={"message": query}
    )
    print(f"User: {query}")
    # Added error handling for responses that don't contain 'answer'
    try:
        print(f"Agent: {response.json()['answer']}\n")
    except KeyError:
        print(f"Agent: Error - Status Code: {response.status_code}, Detail: {response.json().get('detail', 'No detail provided')}\n")
    except Exception as e:
        print(f"Agent: An unexpected error occurred: {e}\n")